Działanie perceptronu polega na klasyfikowaniu danych pojawiających się na wejściu i ustawianiu stosownie do tego wartości wyjścia. Przed używaniem perceptron należy wytrenować, podając mu przykładowe dane na wejście i modyfikując w odpowiedni sposób wagi wejść i połączeń między warstwami neuronów, tak aby wynik na wyjściu przybierał pożądane wartości. Perceptrony mogą klasyfikować dane na zbiory, które są liniowo separowalne. Własność ta uniemożliwia na przykład wytrenowanie złożonego z jednego neuronu perceptronu, który wykonywałby logiczną operację XOR na wartościach wejść. Z matematycznego punktu widzenia wagi perceptronu tworzą wektor normalny, który określa prostą (w przypadku dwóch wejść) lub hiperpłaszczyznę decyzyjną. Trenowanie perceptronu to dopasowanie tej hiperpłaszczyzny do danych wejściowych, aby mógł wskazywać czy punkt należy lub nie należy do zbioru wskazywanego przez hiperpłaszczyznę. Dlatego tak ważne jest, aby dane były liniowo separowalne, inaczej dopasowanie do danych będzie niemożliwe.